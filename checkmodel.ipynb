{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d195ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1.pt -> Accuracy: 0.4299\n",
      "model_10.pt -> Accuracy: 0.7515\n",
      "model_100.pt -> Accuracy: 0.8367\n",
      "model_11.pt -> Accuracy: 0.7481\n",
      "model_12.pt -> Accuracy: 0.7639\n",
      "model_13.pt -> Accuracy: 0.7785\n",
      "model_14.pt -> Accuracy: 0.7816\n",
      "model_15.pt -> Accuracy: 0.8008\n",
      "model_16.pt -> Accuracy: 0.7939\n",
      "model_17.pt -> Accuracy: 0.7982\n",
      "model_18.pt -> Accuracy: 0.7897\n",
      "model_19.pt -> Accuracy: 0.8035\n",
      "model_2.pt -> Accuracy: 0.5104\n",
      "model_20.pt -> Accuracy: 0.8128\n",
      "model_21.pt -> Accuracy: 0.8101\n",
      "model_22.pt -> Accuracy: 0.8116\n",
      "model_23.pt -> Accuracy: 0.8055\n",
      "model_24.pt -> Accuracy: 0.8170\n",
      "model_25.pt -> Accuracy: 0.8197\n",
      "model_26.pt -> Accuracy: 0.8078\n",
      "model_27.pt -> Accuracy: 0.8120\n",
      "model_28.pt -> Accuracy: 0.8259\n",
      "model_29.pt -> Accuracy: 0.8270\n",
      "model_3.pt -> Accuracy: 0.6040\n",
      "model_30.pt -> Accuracy: 0.8267\n",
      "model_31.pt -> Accuracy: 0.8220\n",
      "model_32.pt -> Accuracy: 0.8143\n",
      "model_33.pt -> Accuracy: 0.8282\n",
      "model_34.pt -> Accuracy: 0.8147\n",
      "model_35.pt -> Accuracy: 0.8351\n",
      "model_36.pt -> Accuracy: 0.8313\n",
      "model_37.pt -> Accuracy: 0.8355\n",
      "model_38.pt -> Accuracy: 0.8440\n",
      "model_39.pt -> Accuracy: 0.8324\n",
      "model_4.pt -> Accuracy: 0.6337\n",
      "model_40.pt -> Accuracy: 0.8236\n",
      "model_41.pt -> Accuracy: 0.8224\n",
      "model_42.pt -> Accuracy: 0.8328\n",
      "model_43.pt -> Accuracy: 0.8336\n",
      "model_44.pt -> Accuracy: 0.8294\n",
      "model_45.pt -> Accuracy: 0.8374\n",
      "model_46.pt -> Accuracy: 0.8240\n",
      "model_47.pt -> Accuracy: 0.8371\n",
      "model_48.pt -> Accuracy: 0.8401\n",
      "model_49.pt -> Accuracy: 0.8394\n",
      "model_5.pt -> Accuracy: 0.6641\n",
      "model_50.pt -> Accuracy: 0.8378\n",
      "model_51.pt -> Accuracy: 0.8363\n",
      "model_52.pt -> Accuracy: 0.8309\n",
      "model_53.pt -> Accuracy: 0.8405\n",
      "model_54.pt -> Accuracy: 0.8332\n",
      "model_55.pt -> Accuracy: 0.8371\n",
      "model_56.pt -> Accuracy: 0.8305\n",
      "model_57.pt -> Accuracy: 0.8286\n",
      "model_58.pt -> Accuracy: 0.8405\n",
      "model_59.pt -> Accuracy: 0.8320\n",
      "model_6.pt -> Accuracy: 0.6980\n",
      "model_60.pt -> Accuracy: 0.8421\n",
      "model_61.pt -> Accuracy: 0.8267\n",
      "model_62.pt -> Accuracy: 0.8317\n",
      "model_63.pt -> Accuracy: 0.8297\n",
      "model_64.pt -> Accuracy: 0.8401\n",
      "model_65.pt -> Accuracy: 0.8344\n",
      "model_66.pt -> Accuracy: 0.8424\n",
      "model_67.pt -> Accuracy: 0.8378\n",
      "model_68.pt -> Accuracy: 0.8382\n",
      "model_69.pt -> Accuracy: 0.8336\n",
      "model_7.pt -> Accuracy: 0.6818\n",
      "model_70.pt -> Accuracy: 0.8367\n",
      "model_71.pt -> Accuracy: 0.8282\n",
      "model_72.pt -> Accuracy: 0.8424\n",
      "model_73.pt -> Accuracy: 0.8378\n",
      "model_74.pt -> Accuracy: 0.8382\n",
      "model_75.pt -> Accuracy: 0.8328\n",
      "model_76.pt -> Accuracy: 0.8486\n",
      "model_77.pt -> Accuracy: 0.8394\n",
      "model_78.pt -> Accuracy: 0.8390\n",
      "model_79.pt -> Accuracy: 0.8340\n",
      "model_8.pt -> Accuracy: 0.7007\n",
      "model_80.pt -> Accuracy: 0.8320\n",
      "model_81.pt -> Accuracy: 0.8436\n",
      "model_82.pt -> Accuracy: 0.8424\n",
      "model_83.pt -> Accuracy: 0.8309\n",
      "model_84.pt -> Accuracy: 0.8355\n",
      "model_85.pt -> Accuracy: 0.8417\n",
      "model_86.pt -> Accuracy: 0.8421\n",
      "model_87.pt -> Accuracy: 0.8413\n",
      "model_88.pt -> Accuracy: 0.8409\n",
      "model_89.pt -> Accuracy: 0.8378\n",
      "model_9.pt -> Accuracy: 0.7230\n",
      "model_90.pt -> Accuracy: 0.8359\n",
      "model_91.pt -> Accuracy: 0.8371\n",
      "model_92.pt -> Accuracy: 0.8371\n",
      "model_93.pt -> Accuracy: 0.8386\n",
      "model_94.pt -> Accuracy: 0.8340\n",
      "model_95.pt -> Accuracy: 0.8428\n",
      "model_96.pt -> Accuracy: 0.8270\n",
      "model_97.pt -> Accuracy: 0.8224\n",
      "model_98.pt -> Accuracy: 0.8390\n",
      "model_99.pt -> Accuracy: 0.8459\n",
      "\n",
      "âœ… Best model: ./model\\model_76.pt with accuracy: 0.8486\n",
      "ðŸ“¦ Copied best model to model/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "from dataset import AnimalDataset\n",
    "from models import AdvancedCNN\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "val_dataset = AnimalDataset(root=\"./data\", train=False, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model = AdvancedCNN(num_classes=len(val_dataset.categories))\n",
    "model.to(device)\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_path = None\n",
    "\n",
    "model_dir = \"./model\"\n",
    "\n",
    "for filename in os.listdir(model_dir):\n",
    "    if filename.endswith(\".pt\") and filename.startswith(\"model_\"):\n",
    "        path = os.path.join(model_dir, filename)\n",
    "        state_dict = torch.load(path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "\n",
    "        all_preds, all_targets = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                logits = model(images)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().tolist())\n",
    "                all_targets.extend(targets.tolist())\n",
    "\n",
    "        acc = accuracy_score(all_targets, all_preds)\n",
    "        print(f\"{filename} -> Accuracy: {acc:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model_path = path\n",
    "\n",
    "print(f\"\\nâœ… Best model: {best_model_path} with accuracy: {best_acc:.4f}\")\n",
    "\n",
    "# Optional: Copy to best_model.pt\n",
    "if best_model_path:\n",
    "    import shutil\n",
    "    shutil.copy(best_model_path, os.path.join(model_dir, \"best_model.pt\"))\n",
    "    print(\"ðŸ“¦ Copied best model to model/best_model.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
